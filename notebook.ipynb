{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# COMMON LIBRARIES\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom datetime import datetime\n# from google.colab.patches import cv2_imshow\n\n# DATA SET PREPARATION AND LOADING\nfrom detectron2.data.datasets import register_coco_instances\nfrom detectron2.data import DatasetCatalog, MetadataCatalog\n\n# VISUALIZATION\nfrom detectron2.utils.visualizer import Visualizer\nfrom detectron2.utils.visualizer import ColorMode\n\n# CONFIGURATION\nfrom detectron2 import model_zoo\nfrom detectron2.config import get_cfg\n\n# EVALUATION\nfrom detectron2.engine import DefaultPredictor\nfrom detectron2.evaluation import COCOEvaluator, inference_on_dataset\nfrom detectron2.data import build_detection_test_loader\n\n# TRAINING\nfrom detectron2.engine import DefaultTrainer\n\n# LOGGING\nimport logging\nfrom detectron2.utils.logger import setup_logger","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualizer = Visualizer(image[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\nout = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n# cv2.imshow(out.get_image()[:, :, ::-1])\n\nplt.imshow(cv2.cvtColor(out.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB)) # converting BGR to RGB for using matplotlib\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# TRAIN SET\nTRAIN_DATA_SET_NAME = f\"{DATA_SET_NAME}-train\"\nTRAIN_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"train\")\nTRAIN_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"train\", ANNOTATIONS_FILE_NAME)\n\nregister_coco_instances(\n    name=TRAIN_DATA_SET_NAME, \n    metadata={}, \n    json_file=TRAIN_DATA_SET_ANN_FILE_PATH, \n    image_root=TRAIN_DATA_SET_IMAGES_DIR_PATH\n)\n\n# # TEST SET\n# TEST_DATA_SET_NAME = f\"{DATA_SET_NAME}-test\"\n# TEST_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"test\")\n# TEST_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"test\", ANNOTATIONS_FILE_NAME)\n\n# register_coco_instances(\n#     name=TEST_DATA_SET_NAME, \n#     metadata={}, \n#     json_file=TEST_DATA_SET_ANN_FILE_PATH, \n#     image_root=TEST_DATA_SET_IMAGES_DIR_PATH\n# )\n\n# VALID SET\nVALID_DATA_SET_NAME = f\"{DATA_SET_NAME}-valid\"\nVALID_DATA_SET_IMAGES_DIR_PATH = os.path.join(dataset.location, \"valid\")\nVALID_DATA_SET_ANN_FILE_PATH = os.path.join(dataset.location, \"valid\", ANNOTATIONS_FILE_NAME)\n\nregister_coco_instances(\n    name=VALID_DATA_SET_NAME, \n    metadata={}, \n    json_file=VALID_DATA_SET_ANN_FILE_PATH, \n    image_root=VALID_DATA_SET_IMAGES_DIR_PATH\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"metadata = MetadataCatalog.get(TRAIN_DATA_SET_NAME)\ndataset_train = DatasetCatalog.get(TRAIN_DATA_SET_NAME)\n\ndataset_entry = dataset_train[0]\nimage = cv2.imread(dataset_entry[\"file_name\"])\n\nvisualizer = Visualizer(\n    image[:, :, ::-1],\n    metadata=metadata, \n    scale=0.8, \n    instance_mode=ColorMode.IMAGE_BW\n)\n\nout = visualizer.draw_dataset_dict(dataset_entry)\n# cv2.imshow(out.get_image()[:, :, ::-1])\n\nplt.imshow(cv2.cvtColor(out.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB)) # converting BGR to RGB for using matplotlib\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from detectron2.engine import DefaultPredictor\nfrom detectron2.utils.visualizer import Visualizer\nimport cv2\nimport matplotlib.pyplot as plt\n\n# Load configuration and trained weights\ncfg = get_cfg()\ncfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n\n# Use the trained weights\ncfg.MODEL.WEIGHTS = \"/kaggle/working/output/model_final.pth\"  # Path to your trained model weights\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Adjust as needed (lower if detection is weak)\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = 4  # Set to the number of classes in your microplastic dataset\n\npredictor = DefaultPredictor(cfg)\n\n# Load the new image\nnew_image = cv2.imread(\"/kaggle/input/testing2/2.jpeg\")  # Replace with the path to your image\noutputs = predictor(new_image)\n\n# Visualize the outputs on the image\nv = Visualizer(new_image[:, :, ::-1], metadata=MetadataCatalog.get(TRAIN_DATA_SET_NAME), scale=0.8)\nout = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n\n# Display the output image with detections\nplt.imshow(cv2.cvtColor(out.get_image()[:, :, ::-1], cv2.COLOR_BGR2RGB))\nplt.axis('off')\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}